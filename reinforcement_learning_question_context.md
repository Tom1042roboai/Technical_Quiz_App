# Reinforcement Learning - Context and Overview

## Core Concepts in Reinforcement Learning

### 1. Fundamentals
- **Markov Decision Processes (MDPs)**: States, actions, transitions, rewards
- **Value Functions**: State-value and action-value functions
- **Policies**: Deterministic vs. stochastic policies
- **Bellman Equations**: Foundation of dynamic programming in RL

### 2. Algorithms
- **Model-Based**: Value iteration, policy iteration
- **Model-Free**: Q-learning, SARSA, Monte Carlo methods
- **Policy Gradients**: REINFORCE, Actor-Critic methods
- **Deep RL**: DQN, PPO, SAC, TD3

### 3. Advanced Topics
- **Exploration vs. Exploitation**: Îµ-greedy, UCB, Thompson sampling
- **Multi-Agent RL**: Competitive and cooperative settings
- **Inverse RL**: Learning rewards from demonstrations
- **Hierarchical RL**: Temporal abstraction and skill learning

## Applications
- Game playing (AlphaGo, Dota 2 bots)
- Robotics control
- Resource management
- Autonomous vehicles

## Question Difficulty Distribution

| Difficulty | Count | Percentage | Time Limit (seconds) |
|------------|-------|------------|---------------------|
| Easy       | 10    | 31.25%     | 15                  |
| Medium     | 11    | 34.38%     | 20                  |
| Hard       | 11    | 34.38%     | 25                  |

## Learning Resources
- **Books**: "Reinforcement Learning: An Introduction" by Sutton & Barto
- **Courses**: David Silver's RL course, CS285 (UC Berkeley)
- **Libraries**: OpenAI Gym, Stable Baselines, RLLib
